# server

## client_service

- tcp_node::listen( addr, channel );
- channel이 클라 서비스 액터의 채널이다. 
- 연결되면 프로토콜과 액터 아이디를 부여한다.
- server에 클라이언트 액터로 등록한다.

여기 사이에 다른 액터들과 클라이언트 액터 간의 연결이 들어간다.

- 연결이 종료되면 정리 작업에 들어간다.


### 다른 액터와 연결

클라이언트 액터는 다음의 메세지를 갖고 자기를 알리고 통신을 시작한다.

- req_join_client
- res_join_client

내부 메세지:
- syn_join_client
- syn_leave_client

cs.sub( syn_join_client, cb) 을 immediate로 subscribe해서 통지를 받는다.
syn_join_client의 protocol에 자기 채널을 연결한다.

다른 여러 가지를 생각하기 보다 위와 같이 동작하는 구조를 효율적으로 만든다. 

client_service가 그냥 채널을 protocol에 추가하면 모든 클라이언트의 메세지를 
받게 된다. 이것도 하나의 기능이 될 수 있다. 효율적으로 처리하기위해 
등록된 메세지만 큐에 넣는 최적화를 진행한다. 일부 디버깅에서는 이를 
끄고 모두 다 받아서 통계를 남기거나 측정에 사용할 수 있다.

### 부가 기능

- 하트비트
- 단선처리
- 통계
- 진입율 처리

## cluster_service

또다른 cs이다. 구성에 따라 다른 서버에 연결한다. 
- syn_peer_up
  - server_id
- syn_peer_down (단선과 동일하다)
  - server_id

개별 서비스에서 클러스터 서비스를 통해 전송한다.
- syn_service_up
  - actor_id
  - type : string
  - options : string (json)
- syn_service_down
  - actor_id
  - type : string
  - options : string (json)

## 흐름 

서버가 시작하면 구성 파일에 따라 서비스를 시작한다. 
여기에 cluster_service와 client_service가 포함된다. 

cluster_service가 시작하면 구성에 따라 listen, connect를 진행한다.
syn_peer_up을 받으면 로컬 디렉토리에 등록한다. 

다른 서비스는 cluster_service를 얻어서 cast(syn_service_up)을 한다. 
시작 시에도 하고 syn_peer_up를 받도록 하여 이 때도 전송한다.

cluster_service는 다른 피어들과 서비스 목록을 갖고 있다. 
필요한 곳에서 필요한 대상에 등록하여 통지를 받는다. 

검색은 shared_mutex를 쓰면 효율적으로 할 수 있다. 매우 가끔 갱신되는 
구조이기 때문이다. 그렇게 하기위해 관심있는 서비스 동기화 개수를 적절히
유지하는 것이 필요하다.

검색 후 사용은 구독으로 진행한다. 구독 모델이 메세지 패싱의 핵심이다.

메세지 패싱에서 down / 단선 처리는 매우 중요하다. 가장 중요한 에지 케이스이다.

## locational transparency

로컬로 구성했다가 분산했다가 다시 합치는 걸 동일한 코드로 구성만 바꿔서 가능하다면
매우 편하게 개발할 수 있다. 

`흐름`까지 정리한 내용으로는 이를 달성하기 어렵다. 

서비스 액터들이 결국 클러스터를 형성하므로 이를 얻고 사용할 수 있도록 한다.
서비스 액터 포인터를 리모트 액터에 대해 사용할 수 없으므로 
많이 쓰이는 액터 레퍼런스로 추상화 한다. 

auto srf = server_.get_service_by_type( "match_rank_1");
if ( srf )
{
    server_.bind( srf, down_cb ); // 대상 액터에 대해 shared_lock을 건 상태에서 진행
    srf.sub( msgid, cb ); 
    // ...

    srf.send( );
    // 로컬은 publish, 리모트는 send
}

service_ref는 매우 가벼운 구조로 만들어야 한다. 복사를 사용한다. 
- protocol::ptr, 또는 service::ptr
- local / remote 여부

다운에 대한 콜백은 안전하게 등록할 수 있어야 한다!!!

## 이전 구현과 비교

완전한 주소 기반으로 한 경우:
- 매우 유연하다.
- 주소 오버헤드가 있다.
- 서로 너무 모른다. ==> 이게 가장 큰 어려움이다. 
- 자유롭게 전송 가능하고 중계도 쉽게 된다.
- 클라이언트를 포괄하기 어렵다.

주소 기반은 매력이 있다. cluster_service, client_service로 망을 구성하고 단단하게 한 후
주소를 활용한 프로토콜을 그 위에 올릴 수 있게 한다. 주소를 기반으로 하면 망이 출렁인다.

지금과 유사한 구현:
- handler가 actor와 유사
- cluster_handler가 cluster_service에 해당
- 개념이 일관되지 않고 network를 메세지 전파의 중심으로 잡았다.
- 여전히 아이디 기반으로 동작하는 구조가 많았다.
  - 견고하지 않은 면이 있다. 단선 등의 전파가 불확실하다.
- 지금은 세션(protocol)과 actor가 중심이다.
- 단위 테스트를 구성하지 못 했다. 또는 안 했다. 

핵심 개선들이다.
- 주소 기반이 아닌 protocol과 actor 중심이다.
- 사용하는 쪽에서 주도하고 구독으로 연결한다.

## actor 단일화 

client_service는 actor로 클라이언트들을 actor_ref로 추상화 하거나
protocol이 아닌 client로 사용하기위한 진입 / 진출 서비스를 제공한다.

그 외의 클러스터, 로컬 실행은 액터로 한다. 액터 내부의 구현은 액터가 결정한다.
server 참조를 사용하여 자유롭게 구성할 수 있다.

자식 액터들을 생성하고 관리하는 기능도 각 액터에서 구현한다.
미리 만들어진 구조를 둘 수도 있지만 의미를 연결하는 작업이 또 추가되어야 한다.

cluster_service도 actor로 인접 서버 (피어)에 연결하거나 연결을 받고
up / down을 전파한다. 피어 전송 기능을 갖는다.

actor는 clustered option을 갖는다. clusterd option을 갖는 액터들은 
up / down을 피어를 통해 전파한다. service란 이름이 붙는 액터들을 
clustered option을 갖는 액터로 한다.

This is simpler. Thus it is better.

## 단위 테스트 

단위 테스트를 쉽게 구성할 수 있는가를 설계 품질을 판단하는 중요 근거롤 삼아야 한다.

```c++
server s;

auto ap = s.create<test_actor>();

auto aref = s.get_actor_by_type("test");
// auto arefs = s.get_actor_by_cond( cond );
CHECK(aref);

aref.send(msg);

CHECK(ap->received == true);
```

위 코드는 리모트 액터, 클라이언트 액터에 대해서 동일하게 동작한다.

```c++
server s;
s.get_node().listen("0.0.0.0:7707", ch);
```

실제 진행을 해봐야 알겠으나 actor / protocol 중심을 유지한다.


## 정리 

- actor 
- protocol

두 개만 남긴다. 나머지는 잊는다.

- cluster_service
- client_service

두 가지로 망을 액터로 추상화 한다. actor_ref이다.


